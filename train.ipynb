{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQieet9XHu7L"
      },
      "source": [
        "## Train and stores embeddings\n",
        "\n",
        "this colab loads a the code from git, trains GMM/GVAE model and stores the embeddings for further analysis\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITrUznBr7Szj",
        "outputId": "72ef02ab-b7da-4618-c178-9c3a289cf00e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAe9hhwQdOxX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b66b134-bf5b-4a75-9037-7b417c661c10"
      },
      "source": [
        "#@title Set up and imports\n",
        "from google.colab import drive \n",
        "import os \n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import models\n",
        "from tensorflow.python.keras.engine import node\n",
        "from tensorflow.python.keras.engine.node import Node \n",
        "import tensorflow_probability as tfp\n",
        "tfd = tfp.distributions\n",
        "\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "\n",
        "# notebook's location in the repo\n",
        "WORKING_PATH = './drive/MyDrive/GGMbetaFactorVAE/GVAE/' \n",
        "\n",
        "if 'first_run' not in locals():\n",
        "  drive.mount('/content/drive/')\n",
        "  os.chdir(WORKING_PATH)\n",
        "\n",
        "  first_run = False"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zud1C-a9eySL"
      },
      "source": [
        "from src.models import GM_VGAE, VGAE\n",
        "from src import utils "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItHA4d8VlRzj"
      },
      "source": [
        "## Loading data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQNdTbuqM7Vu",
        "outputId": "29724558-3364-4b81-b9ec-f16294b54dff"
      },
      "source": [
        "## Loads data\n",
        "\n",
        "network_path = 'data/diseasome/disease_network_adj.npy'\n",
        "labels_path = 'data/diseasome/disease_network_types.npy'\n",
        "output_path = 'data/saved/diseasome/model/'\n",
        "\n",
        "data_params = dict(network_path = network_path,\n",
        "                   labels_path = labels_path,\n",
        "                   use_features=True,\n",
        "                   auxiliary_prediction_task=False,\n",
        "                   epochs=1000)\n",
        "\n",
        "res = utils.load_and_build_dataset(data_params)\n",
        "adj = res['adj']\n",
        "aux_targets = res['target']\n",
        "dataset = res['dataset']\n",
        "val_edges = res['val_edges']\n",
        "val_edges_false = res['val_edges_false']\n",
        "test_edges = res['test_edges']\n",
        "test_edges_false = ['test_edges_false']\n",
        "\n",
        "adj_orig = adj - sp.dia_matrix((adj.diagonal()[np.newaxis, :], [0]), shape=adj.shape)\n",
        "adj_orig.eliminate_zeros()\n",
        "adj_orig = adj_orig.toarray()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DONE: train_edges\n",
            "DONE: test_edges_false\n",
            "DONE: val_edges_false\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soy83g3mlVfR"
      },
      "source": [
        "## Defining a train step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IS1EdpVPpbi"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "\n",
        "def get_roc_score(edges_pos, edges_neg, emb):\n",
        "\n",
        "    def sigmoid(x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    # Predict on test set of edges\n",
        "    adj_rec = np.dot(emb, emb.T)\n",
        "    preds = []\n",
        "    pos = []\n",
        "    for e in edges_pos:\n",
        "        preds.append(sigmoid(adj_rec[e[0], e[1]]))\n",
        "        pos.append(adj_orig[e[0], e[1]])\n",
        "\n",
        "    preds_neg = []\n",
        "    neg = []\n",
        "    for e in edges_neg:\n",
        "        preds_neg.append(sigmoid(adj_rec[e[0], e[1]]))\n",
        "        neg.append(adj_orig[e[0], e[1]])\n",
        "\n",
        "    preds_all = np.hstack([preds, preds_neg])\n",
        "    labels_all = np.hstack([np.ones(len(preds)), np.zeros(len(preds_neg))])\n",
        "    roc_score = roc_auc_score(labels_all, preds_all)\n",
        "    ap_score = average_precision_score(labels_all, preds_all)\n",
        "\n",
        "    return roc_score, ap_score"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zos-rqECKeTt"
      },
      "source": [
        "\n",
        "def train_step(adj_normalized, features, adj_label, norm, pos_weight, experiment_params, aux_targets=None):   \n",
        "    \"\"\" Defines basic training step \"\"\"\n",
        "\n",
        "    model_type = experiment_params['model']\n",
        "    assert model_type in ['VGAE', 'GM_VGAE']\n",
        "    assert ((model_type=='VGAE' and aux_targets is None) or (model_type=='GM_VGAE'))\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        beta = 1\n",
        "        adj_label = tf.reshape(adj_label, [-1])\n",
        "\n",
        "        Q, Q_log_std, reconstructed = model(adj_normalized, features)\n",
        "        reconstruction_loss = norm * tf.math.reduce_mean(\n",
        "            tf.nn.weighted_cross_entropy_with_logits(labels=adj_label, logits=reconstructed, pos_weight=pos_weight)\n",
        "        ) \n",
        "        node_num = adj_normalized.shape[0] \n",
        "        if model_type == 'VGAE':\n",
        "            # kl = - (0.5 / node_num) * tf.math.reduce_mean(\n",
        "            #     tf.math.reduce_sum(1 + 2 * Q_log_std - tf.math.square(Q.mean()) - tf.math.square(Q.stddev()), axis=1)\n",
        "            # ) \n",
        "\n",
        "            kl = tf.reduce_mean(tfd.kl_divergence(Q, model.prior)) / node_num\n",
        "            classification_loss = 0\n",
        "        else:\n",
        "            kl = tf.reduce_mean(utils.mc_kl_divergence(Q, model.prior)) / node_num\n",
        "            # kl = tf.reduce_mean(kl_divergence_upper_bound(Q, model.prior)) / node_num\n",
        "\n",
        "            if experiment_params['auxiliary_prediction_task']:\n",
        "                classification_loss = tf.reduce_mean(\n",
        "                    tf.nn.softmax_cross_entropy_with_logits(logits=model.cy_logits, labels=aux_targets)\n",
        "                )\n",
        "                classification_accuracy = tf.reduce_mean(\n",
        "                    tf.cast(tf.argmax(model.cy_logits, axis=1)==tf.argmax(aux_targets, axis=1), tf.float32), axis=0\n",
        "                )\n",
        "            else: \n",
        "                classification_loss = 0\n",
        "                classification_accuracy = None\n",
        "        \n",
        "        vae_loss = reconstruction_loss + beta*kl + classification_loss\n",
        "\n",
        "    gradients = tape.gradient(vae_loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "    # metrics\n",
        "    RECONSTRUCTION.append(reconstruction_loss.numpy())\n",
        "    KL_LOSSES.append(kl.numpy())\n",
        "    LOSSES.append(vae_loss.numpy())\n",
        "    if experiment_params['auxiliary_prediction_task']:\n",
        "        CLASSIFICATION_LOSSES.append(classification_loss.numpy())\n",
        "        CLASSIFICATION_ACCURACIES.append(classification_accuracy.numpy())\n",
        "\n",
        "    if experiment_params['model'] == 'GM_VGAE':\n",
        "        # taking the mean of the mixture doesn't work in this case.\n",
        "        # NOTE we could approximate the mean \n",
        "        emb = tf.squeeze(Q.sample(1), axis=0).numpy() \n",
        "    else: \n",
        "        emb = Q.mean().numpy()\n",
        "\n",
        "    roc_curr, ap_curr = get_roc_score(val_edges, val_edges_false, emb)\n",
        "    VAL_ROC_SCORE.append(roc_curr)\n",
        "    VAL_AP_SCORE.append(ap_curr)\n",
        "    "
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_39_Walle6X"
      },
      "source": [
        "## Experiment "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4f2UZi3KV-R"
      },
      "source": [
        "## Initializes experiment \n",
        "\n",
        "experiment_params = dict(\n",
        "    learning_rate=1e-3,\n",
        "    epochs=data_params['epochs'],\n",
        "    hidden=32,\n",
        "    latent_size=16,\n",
        "    dropout=0.2 ,\n",
        "    model='GM_VGAE',\n",
        "    # model='VGAE',\n",
        "    use_features=data_params['use_features'],      \n",
        "    auxiliary_prediction_task=data_params['auxiliary_prediction_task'],\n",
        "    save_path=output_path \n",
        ")\n",
        "\n",
        "# auxiliary prediction can only be done with GM_VAE\n",
        "assert not (experiment_params['model']=='VGAE' and experiment_params['auxiliary_prediction_task'])\n",
        "\n",
        "    \n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=experiment_params['learning_rate'])\n",
        "RECONSTRUCTION = []\n",
        "KL_LOSSES = []\n",
        "LOSSES = []\n",
        "CLASSIFICATION_LOSSES = []\n",
        "CLASSIFICATION_ACCURACIES = []\n",
        "VAL_ROC_SCORE = []\n",
        "VAL_AP_SCORE = []\n",
        "\n",
        "pos_weight = float(adj.shape[0] * adj.shape[0] - adj.sum()) / adj.sum()\n",
        "norm = adj.shape[0] * adj.shape[0] / float((adj.shape[0] * adj.shape[0] - adj.sum()) * 2)\n",
        "\n",
        "\n",
        "class_num = aux_targets.shape[1]\n",
        "node_num = adj.shape[0]\n",
        "\n",
        "if experiment_params['model'] == 'VGAE':\n",
        "    model = VGAE(node_num=node_num, \n",
        "                  hidden=experiment_params['hidden'], \n",
        "                  latent_size=experiment_params['latent_size'],\n",
        "                  dropout=experiment_params['dropout'])\n",
        "elif experiment_params['model'] == 'GM_VGAE':\n",
        "    model = GM_VGAE(node_num=node_num, \n",
        "                    class_num=class_num, \n",
        "                    latent_size=experiment_params['latent_size'],\n",
        "                    hidden=experiment_params['hidden'],\n",
        "                    dropout=experiment_params['dropout'])\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSu02VzvInuS",
        "outputId": "12bfc297-e2ae-4ec0-da1e-993dac514a65"
      },
      "source": [
        "#@title Training loop\n",
        "\n",
        "e = 0\n",
        "for adj_norm, features, label in dataset:\n",
        "    if experiment_params['model'] == 'GM_VGAE':\n",
        "        train_step(adj_norm, features, \n",
        "                label, norm, pos_weight, \n",
        "                experiment_params, aux_targets=aux_targets)\n",
        "    else:\n",
        "         train_step(adj_norm, features, \n",
        "                label, norm, pos_weight, \n",
        "                experiment_params)\n",
        "    \n",
        "    if e % 100 == 0:\n",
        "        if experiment_params['auxiliary_prediction_task']:\n",
        "            print(\n",
        "                'total: {:.2f}, rec: {:.2f}, classification: {:.2f}, kl_loss: {:.2f}'.format(\n",
        "                LOSSES[-1], RECONSTRUCTION[-1], CLASSIFICATION_ACCURACIES[-1], KL_LOSSES[-1]))\n",
        "        else:\n",
        "            print('total: {:.2f}, rec: {:.2f}, kl_loss: {:.2f}'.format(\n",
        "                LOSSES[-1], RECONSTRUCTION[-1], KL_LOSSES[-1]))\n",
        "\n",
        "    e +=1\n",
        "\n",
        "# test_roc, test_ap = get_roc_score(test_edges, test_edges_false, )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total: 1.90, rec: 1.90, kl_loss: 0.00\n",
            "total: 1.11, rec: 1.10, kl_loss: 0.00\n",
            "total: 0.76, rec: 0.74, kl_loss: 0.02\n",
            "total: 0.71, rec: 0.68, kl_loss: 0.03\n",
            "total: 0.62, rec: 0.59, kl_loss: 0.03\n",
            "total: 0.56, rec: 0.52, kl_loss: 0.03\n",
            "total: 0.53, rec: 0.49, kl_loss: 0.04\n",
            "total: 0.51, rec: 0.48, kl_loss: 0.04\n",
            "total: 0.50, rec: 0.47, kl_loss: 0.04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUKix4l1SeXp"
      },
      "source": [
        "#@title Diagnosis plots - \n",
        "#@markdown \n",
        "\n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns \n",
        "from sklearn.manifold import TSNE\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "Q = model.Q\n",
        "z = tf.squeeze(Q.sample(1))\n",
        "    \n",
        "z_proj = TSNE(n_components=2).fit_transform(z)\n",
        "    \n",
        "\n",
        "fig, axs = plt.subplots(3, 2, figsize=(20, 15))\n",
        "axs = axs.flatten()\n",
        "\n",
        "axs[0].plot(KL_LOSSES)\n",
        "axs[0].set_title('KL loss')\n",
        "\n",
        "axs[1].plot(RECONSTRUCTION)\n",
        "axs[1].set_title('Reconstruction loss')\n",
        "\n",
        "if experiment_params['auxiliary_prediction_task']:\n",
        "    # axs[2].plot(CLASSIFICATION_LOSSES)\n",
        "    # axs[2].set_title('Classification loss')\n",
        "\n",
        "    axs[2].plot(CLASSIFICATION_ACCURACIES)\n",
        "    axs[2].set_title('Classification accuracy')\n",
        "\n",
        "if 'z_proj' in locals():\n",
        "    # if experiment_params['auxiliary_prediction_task']:\n",
        "    sns.scatterplot(\n",
        "        x=z_proj[:, 0], y=z_proj[:, 1],\n",
        "        palette=sns.color_palette(\"hls\", aux_targets.shape[1]),\n",
        "        hue=np.where(aux_targets==1)[1],\n",
        "        legend='full', \n",
        "        alpha=0.8,\n",
        "        ax=axs[3]\n",
        "    )\n",
        "    # else:\n",
        "    #     sns.scatterplot(\n",
        "    #         x=z_proj[:, 0], y=z_proj[:, 1],\n",
        "    #         legend='full', \n",
        "    #         alpha=0.8,\n",
        "    #         ax=axs[3]\n",
        "    #     )\n",
        "\n",
        "    axs[3].set_title('TSNE projection')\n",
        "\n",
        "def moving_average(x, w):\n",
        "    return np.convolve(x, np.ones(w), 'valid') / w\n",
        "\n",
        "axs[4].set_title('validation ROC score')\n",
        "axs[4].plot(VAL_ROC_SCORE)\n",
        "axs[4].plot(moving_average(VAL_ROC_SCORE, 20))\n",
        "\n",
        "axs[5].set_title('validation AP score')\n",
        "axs[5].plot(VAL_AP_SCORE)\n",
        "axs[5].plot(moving_average(VAL_AP_SCORE, 20))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJ_glVaAJ67q"
      },
      "source": [
        "# saves model\n",
        "\n",
        "model.save_weights(experiment_params['save_path'])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsmBqL5p8hHK"
      },
      "source": [
        "## TODO "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGNKudY48dfh"
      },
      "source": [
        "## TODO what is going on with roc and precision? train a simple gvae, see what happens \n",
        "## TODO generate save_path string from experiment params \n",
        "## TODO script for multiple training runs with different experiment params and checkpoint generation  \n",
        "## TODO when we're sampling in the GMVGAE we might as well sample the elbo directly "
      ],
      "execution_count": 10,
      "outputs": []
    }
  ]
}